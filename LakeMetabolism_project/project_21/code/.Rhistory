all <- all[,c("Date_time", "Pond", "Day", "Depthm", "ChlorophyllRFU.1", "CondScm", "SpCondScm",
"fDOMRFU", "ODOmgL", "ODOsat", "BGAPCRFU", "pH", "TempC")]
# rename
setnames(all, c("Date_time", "Pond", "Day", "Depth_m", "Chlorophyll_RFU", "Cond_uScm", "SpCond_uScm",
"fDOM_RFU", "ODO_mgL", "ODO_sat", "BGAPC_RFU", "pH", "Temp_C"))
# debug: remove duplicate values
all <- unique(all, by=c("Pond", "Date_time"))
# check the variable types
str(all)
# Step 3: cut the profiles -----------------------------------------------------
# Here, I will cut the profile subsets of the individual ponds to the relevant
# range
# Check whether the profiling was done correctly in all ponds
# Check if all Ponds have at least 1 measurement of Depth greater or equal
# to 1m
sapply(unique(all$Pond), function(pond) {
any(all$Depth_m[all$Pond == pond] >= 1)
}) # Since some ponds are very shallow, I'll still include all the ponds for
# the profile cutting
# The current cutting is as follows:
# First, I individually selected a starting level where I cut, depending
# on the pond. Sometimes, the sondes were initially held at a deeper point
# before starting profiling.
# After cutting away everything below the threshold, I search the maximum depth
# and keep only the sequence starting from the threshold up to the maximum depth
# Then, I order the values by increasing depth, not time (sometimes, the sampling person
# might lift the sonde up a bit by accident).
# Initialize an empty list to store results for each pond
result_list <- list()
# Pick individual thresholds
thresholds <- c("B1P1"=0.9, "B1P2"=0.325, "B1P3"=0.75,  "B1P4" = 0.6, "B2P2"=1,
"B2P3"=1, "B2P4"=0.5, "B3P0"=0.6, "B3P1"=0.6, "B3P2"=0.5, "B3P3"=1,
"B3P4"=0.6, "EFL2"=1, "ERL122"=1, "ERL152"=1, "ERL186"=0.52, "ERL32"=1.25,
"ERL33"=1, "ERL5"=1, "ERL85"=1, "ERL87"=0.55, "ERL88"=0.325 , "L26"=1.25)
all2 <- subset(all, Pond == "B1P1")
all2
View(all2)
all2 <- all2[Depth_m >= 0.9,]
seq_len(which.max(all2$Depth_m))
all2 <- all2[seq_len(which.max(all2$Depth_m))]
all2 <- all2 %>%
arrange(Pond, Depth_m)
################################################################################
# This script is meant to import, cut, store, and plot all sonde profiles
# from 2021 in Greenland.
# Please note, that it is important that the .csv files are encoded
# as UTF-8, otherwise the code will not work.
# In excel, one can save a file as UTF-8 .csv.
# I converted some of the files imported to UTF-8 beforehand.
################################################################################
# Step 0: set up R-script ------------------------------------------------------
rm(list= ls())
# Packages ad functions from Moritz Luehrig's paper
source("../../Literature/Moritz_Luehrig_paper_stuff/methods_packages.R")
require(GGally)
require(gridExtra)
# For images
require(grDevices)
# Step 1: merge all raw data files into a single big one -----------------------
# Please ensure that all files are UTF-8 encoded (you'll get an error message
# that hints to that problem if you try run the following script)
path = "../data/sondes_profiling_raw"
filenames <- list.files(path=path, pattern=".csv")
files<-data.table(NULL)
system.time(for(i in filenames){
filepath <- file.path(path,paste(i,sep=""))
dummy1<-fread(filepath,
colClasses = "character" ,
sep = ";",
header = FALSE,
fill=TRUE,
encoding ="UTF-8",
quote = FALSE)
rownumb<-dummy1[V1 %like% "(MM/DD/YYYY)", which=TRUE]+1
colname<-dummy1[V1 %like% "(MM/DD/YYYY)"]
colname <- iconv(as.character(colname), from = "UTF-8", to = "UTF-8//IGNORE")
colname <- gsub("µ", "", colname)  # Remove mu character
colname <- gsub("°", "", colname)  # Remove degree symbol
colname<-gsub(" ", "",(gsub("[[:punct:]]", "",c(lapply(colname,as.character)))))
colname <- make.unique(colname)  # Ensure unique column names
colname<-unlist(strsplit(colname,"\t"))
dummy2<-dummy1[rownumb:.N]
setnames(dummy2,colname)
dummy2[,(colname[c(3,5:length(dummy2))]):=lapply(.SD, as.numeric),.SDcols=colname[c(3,5:length(dummy2))]]
dummy2$Pond<-sub("_Sept.*", "", i) # Extract pond
dummy2$Source_file<-i # Extract source file
dummy2$Day <- str_extract(i, "(Sept\\d{1,2})") # Extract day
files<-rbindlist(list(files, dummy2), fill=TRUE)
})
all <- files
# select columns to keep
# Here, I had 2 columns for both Chlorophyll RFU and Chlorophyll mg/L
# I took the column of Chlorophyll RFU that had the plausible values
# I won't include Chlorophyll mg/L
all <- all[,c("DateMMDDYYYY", "TimeHHMMSS", "Pond", "Day", "Depthm", "ChlorophyllRFU.1", "CondScm", "SpCondScm",
"fDOMRFU", "ODOmgL", "ODOsat", "BGAPCRFU", "pH", "TempC")]
# Step 2: format time, rename columns ------------------------------------------
# format date & time
all$DateMMDDYYYY<-mdy(all$DateMMDDYYYY)
all$Date_time<-ymd_hms(paste(all$DateMMDDYYYY, all$TimeHHMMSS))
setnames(all,1:2,c("Date","Time"))
# exclude "Date" and "Time"
all <- all[,!c("Date", "Time")]
# reorder
all <- all[,c("Date_time", "Pond", "Day", "Depthm", "ChlorophyllRFU.1", "CondScm", "SpCondScm",
"fDOMRFU", "ODOmgL", "ODOsat", "BGAPCRFU", "pH", "TempC")]
# rename
setnames(all, c("Date_time", "Pond", "Day", "Depth_m", "Chlorophyll_RFU", "Cond_uScm", "SpCond_uScm",
"fDOM_RFU", "ODO_mgL", "ODO_sat", "BGAPC_RFU", "pH", "Temp_C"))
# debug: remove duplicate values
all <- unique(all, by=c("Pond", "Date_time"))
# check the variable types
str(all)
# Step 3: cut the profiles -----------------------------------------------------
# Here, I will cut the profile subsets of the individual ponds to the relevant
# range
# Check whether the profiling was done correctly in all ponds
# Check if all Ponds have at least 1 measurement of Depth greater or equal
# to 1m
sapply(unique(all$Pond), function(pond) {
any(all$Depth_m[all$Pond == pond] >= 1)
}) # Since some ponds are very shallow, I'll still include all the ponds for
# the profile cutting
# The current cutting is as follows:
# First, I individually selected a starting level where I cut, depending
# on the pond. Sometimes, the sondes were initially held at a deeper point
# before starting profiling.
# After cutting away everything below the threshold, I search the maximum depth
# and keep only the sequence starting from the threshold up to the maximum depth
# Then, I order the values by increasing depth, not time (sometimes, the sampling person
# might lift the sonde up a bit by accident).
# Initialize an empty list to store results for each pond
result_list <- list()
# Pick individual thresholds
thresholds <- c("B1P1"=0.9, "B1P2"=0.325, "B1P3"=0.75,  "B1P4" = 0.6, "B2P2"=1,
"B2P3"=1, "B2P4"=0.5, "B3P0"=0.6, "B3P1"=0.6, "B3P2"=0.5, "B3P3"=1,
"B3P4"=0.6, "EFL2"=1, "ERL122"=1, "ERL152"=1, "ERL186"=0.52, "ERL32"=1.25,
"ERL33"=1, "ERL5"=1, "ERL85"=1, "ERL87"=0.55, "ERL88"=0.325 , "L26"=1.25)
# Loop through each unique pond
for (pond in unique(all$Pond)) {
# Subset the data for the current pond
pond_data <- all[Pond == pond]
# Get the unique depth threshold for the current pond
threshold <- thresholds[pond]
# Filter out Depth_m below the unique threshold for this pond
pond_data <- pond_data[Depth_m >= threshold]
# Cut off all values after the maximum depth
pond_data <- pond_data[seq_len(which.max(pond_data$Depth_m))]  # Retain up to the maximum depth
# Optionally, you could reset the row names
rownames(pond_data) <- NULL
# Store the result in the list
result_list[[pond]] <- pond_data
}
# Combine all subsets back into a single data.table if needed
all <- rbindlist(result_list)
# Step 0: set up R-script ------------------------------------------------------
rm(list= ls())
# Packages ad functions from Moritz Luehrig's paper
source("../../Literature/Moritz_Luehrig_paper_stuff/methods_packages.R")
# Estimating lake metabolism with free-water oxygen
# See "report_analysis_metabolism_B3P3_2022" for further details
require(LakeMetabolizer)
# For plotting
require(GGally)
# Imputation of NAs for time-series (our NAs are due to outlier processing)
require(imputeTS)
# For Bayesian lake metabolism modeling
require(R2jags) # Also, installing JAGS is necessary under
require(ggpubr)
require(grid) # Arranging multiple plots
require(grDevices) # Saving png files
# This is our complete dataset of the sondes measurements 2021
# Measurement Interval: 2 minutes
all <- fread("../data/processed_data_sondes/ponds_sonde_data_all.txt")
# Importing the metadata
# Wind and irradiation
# Measurement Interval: 1 hour, hourly averages
# Source: QAS_L automated weather station near Narsarsuaq
# https://dataverse.geus.dk/dataset.xhtml?persistentId=doi:10.22008/FK2/IW73UU
# wind sensor height: 2.65 + 0.4 = ca 3.05m
meta <- fread("../data/metadata_metabolism_analysis/metadata_2021.txt")
# Select columns to keep from our time series
all <- all[, c("Pond", "Date_time", "ODO_mgL", "Temp_C")]
# Select Pond B1P1 (Treatment: Fish)
all <- subset(all, Pond == "ERL85")
# Rename
all <- setnames(all,c("Pond", "datetime", "do.obs", "wtr"))
View(all)
View(meta)
# choose desired period for the metadata
meta <- meta[c(1:169),]
# rename
meta <- setnames(meta,c("datetime", "dsr_cor", "wsp"))
meta <- meta %>%
mutate(datetime = as.POSIXct(format(datetime, format = "%Y-%m-%d %H:01:00", tz = "UTC"), tz = "UTC"))
# Create a new inflated dataset with measurements every 2 minutes
# The hourly mean will be assigned to every observation (2min-interval) within that hour
meta_ext <- meta %>%
complete(datetime = seq(from = min(datetime), to = max(datetime), by = "2 min"))
# Fill the missing wind speed and irradiation values with the corresponding hourly values using 'fill'
meta_ext <- meta_ext %>%
fill(wsp, .direction = "up") %>%
fill(dsr_cor, .direction = "up")
# Isolate the desired period for metabolism estimation
all <- all[c(121:5160),]
View(meta_ext)
View(meta_ext)
View(meta)
# Shift wind speed and irradiation one row up
meta_ext <- meta_ext %>%
mutate(wsp = lead(wsp, default = last(wsp))) %>%
mutate(dsr_cor = lead(dsr_cor, default = last(dsr_cor)))
# Ommit last row (not included in our timeseries)
meta_ext <- meta_ext[-nrow(meta_ext), ]
# Reset row names for the final result
rownames(meta_ext) <- NULL
# Step 2: merge the 2 datasets -------------------------------------------------
all <- merge(meta_ext, all, by = "datetime")
# 113 NAs (due to outlier processing)
colSums(is.na(all))
# Make a timeseries object
ts <- ts(all$do.obs, frequency = 720)
# Impute with imputeTS
imp_all <- na_ma(ts) # use this function!
imp_all <- data.table(imp_all)
imp_all$datetime <- all$datetime
# Check for missing values in the imputed dataset
sum(is.na(imp_all)) # No missing values anymore
# Check imputation by plotting the original and the imputed dataset
plot(x = all$datetime, y = all$do.obs, type = "l", col = "blue", lwd = 2)
lines(x = imp_all$datetime, y = imp_all$imp_all, type = "l",
col = rgb(1, 0, 0, alpha = 0.3), lwd = 2)
# Replace original column with imputed column
all$do.obs <- imp_all$imp_all
sum(is.na(all))
# This function needs specific column names
all$wnd <- all$wsp
all$wsp <- NULL
# Normalize wind to 10m sensor height
wind.scale <- wind.scale(all, wnd.z = 3.05)
all <- merge(all, wind.scale, by = "datetime")
all$wnd <- all$wnd_10
all$wnd_10 <- NULL
# Also only the 2 columns of interest, otherwise it gets confused
all.600 <- all[,c("datetime","wnd")]
k600.vachon <- k.vachon(all.600, lake.area = 18200)
# Merge
all <- merge(all, k600.vachon, by = "datetime")
kgas <- k600.2.kGAS(all)
# Merge
all <- merge(all, kgas, by = "datetime")
# only keep k.gas
all$k600 <- NULL
o2.sat <- o2.at.sat(all[,c('datetime','wtr')])
# Merge
all <- merge(all, o2.sat, by = "datetime")
# Derive par from sw
par <- sw.to.par(all, sw.col = "dsr_cor")
rownames(par) <- NULL
# Merge
all <- merge(all, par[,c("datetime", "par")], by = "datetime")
all2 <- all
all2$z.mix <- 0.5
all3 <-all
all3$z.mix <- 1
all4 <- all
all4$z.mix <- 2
all5 <- all
all5$z.mix <- 3
all6 <- all
all6$z.mix <- 4
all7 <- all
all7$z.mix <- 5
all8 <- all
all8$z.mix <- 6
all9 <- all
all9$z.mix <- 7
all2 <- all2[,c("datetime", "do.obs", "do.sat", "k.gas", "z.mix", "par", "wtr")]
all3 <- all3[,c("datetime", "do.obs", "do.sat", "k.gas", "z.mix", "par", "wtr")]
all4 <- all4[,c("datetime", "do.obs", "do.sat", "k.gas", "z.mix", "par", "wtr")]
all5 <- all5[,c("datetime", "do.obs", "do.sat", "k.gas", "z.mix", "par", "wtr")]
all6 <- all6[,c("datetime", "do.obs", "do.sat", "k.gas", "z.mix", "par", "wtr")]
all7 <- all7[,c("datetime", "do.obs", "do.sat", "k.gas", "z.mix", "par", "wtr")]
all8 <- all8[,c("datetime", "do.obs", "do.sat", "k.gas", "z.mix", "par", "wtr")]
all9 <- all9[,c("datetime", "do.obs", "do.sat", "k.gas", "z.mix", "par", "wtr")]
# Mixed layer depth 0.5m over the whole observation period
bayesian.res_0.5 <- metab(all2, method="bayesian", wtr.name='wtr', do.obs.name='do.obs',
irr.name='par', z.mix = "z.mix", k.gas.name = "k.gas",
do.sat.name = "do.sat")
# Mixed layer depth 1m over the whole observation period
bayesian.res_1 <- metab(all3, method="bayesian", wtr.name='wtr', do.obs.name='do.obs',
irr.name='par', z.mix = "z.mix", k.gas.name = "k.gas",
do.sat.name = "do.sat")
# Mixed layer depth 2m over the whole observation period
bayesian.res_2 <- metab(all4, method="bayesian", wtr.name='wtr', do.obs.name='do.obs',
irr.name='par', z.mix = "z.mix", k.gas.name = "k.gas",
do.sat.name = "do.sat")
# Mixed layer depth 3m over the whole observation period
bayesian.res_3 <- metab(all5, method="bayesian", wtr.name='wtr', do.obs.name='do.obs',
irr.name='par', z.mix = "z.mix", k.gas.name = "k.gas",
do.sat.name = "do.sat")
# Mixed layer depth 0.5m over the whole observation period
bayesian.res_4 <- metab(all6, method="bayesian", wtr.name='wtr', do.obs.name='do.obs',
irr.name='par', z.mix = "z.mix", k.gas.name = "k.gas",
do.sat.name = "do.sat")
# Mixed layer depth 1m over the whole observation period
bayesian.res_5 <- metab(all7, method="bayesian", wtr.name='wtr', do.obs.name='do.obs',
irr.name='par', z.mix = "z.mix", k.gas.name = "k.gas",
do.sat.name = "do.sat")
# Mixed layer depth 2m over the whole observation period
bayesian.res_6 <- metab(all8, method="bayesian", wtr.name='wtr', do.obs.name='do.obs',
irr.name='par', z.mix = "z.mix", k.gas.name = "k.gas",
do.sat.name = "do.sat")
# Mixed layer depth 3m over the whole observation period
bayesian.res_7 <- metab(all9, method="bayesian", wtr.name='wtr', do.obs.name='do.obs',
irr.name='par', z.mix = "z.mix", k.gas.name = "k.gas",
do.sat.name = "do.sat")
# Get standard deviations of estimates
bayesian.sd_0.5 <- attr(bayesian.res_0.5, "metab.sd")
bayesian.sd_1 <- attr(bayesian.res_1, "metab.sd")
bayesian.sd_2 <- attr(bayesian.res_2, "metab.sd")
bayesian.sd_3 <- attr(bayesian.res_3, "metab.sd")
bayesian.sd_4 <- attr(bayesian.res_4, "metab.sd")
bayesian.sd_5 <- attr(bayesian.res_5, "metab.sd")
bayesian.sd_6 <- attr(bayesian.res_6, "metab.sd")
bayesian.sd_7 <- attr(bayesian.res_7, "metab.sd")
bayesian.res_0.5$Date <- as.Date(paste(bayesian.res_0.5$year, "-", bayesian.res_0.5$doy, sep = ""), format = "%Y-%j")
bayesian.res_1$Date <- as.Date(paste(bayesian.res_1$year, "-", bayesian.res_1$doy, sep = ""), format = "%Y-%j")
bayesian.res_2$Date <- as.Date(paste(bayesian.res_2$year, "-", bayesian.res_2$doy, sep = ""), format = "%Y-%j")
bayesian.res_3$Date <- as.Date(paste(bayesian.res_3$year, "-", bayesian.res_3$doy, sep = ""), format = "%Y-%j")
bayesian.res_4$Date <- as.Date(paste(bayesian.res_4$year, "-", bayesian.res_4$doy, sep = ""), format = "%Y-%j")
bayesian.res_5$Date <- as.Date(paste(bayesian.res_5$year, "-", bayesian.res_5$doy, sep = ""), format = "%Y-%j")
bayesian.res_6$Date <- as.Date(paste(bayesian.res_6$year, "-", bayesian.res_6$doy, sep = ""), format = "%Y-%j")
bayesian.res_7$Date <- as.Date(paste(bayesian.res_7$year, "-", bayesian.res_7$doy, sep = ""), format = "%Y-%j")
View(bayesian.res_0.5)
bayesian.sd_0.5$Date <- as.Date(paste(bayesian.sd_0.5$year, "-", bayesian.sd_0.5$doy, sep = ""), format = "%Y-%j")
bayesian.sd_1$Date <- as.Date(paste(bayesian.sd_1$year, "-", bayesian.sd_1$doy, sep = ""), format = "%Y-%j")
bayesian.sd_2$Date <- as.Date(paste(bayesian.sd_2$year, "-", bayesian.sd_2$doy, sep = ""), format = "%Y-%j")
bayesian.sd_3$Date <- as.Date(paste(bayesian.sd_3$year, "-", bayesian.sd_3$doy, sep = ""), format = "%Y-%j")
bayesian.sd_4$Date <- as.Date(paste(bayesian.sd_4$year, "-", bayesian.sd_4$doy, sep = ""), format = "%Y-%j")
bayesian.sd_5$Date <- as.Date(paste(bayesian.sd_5$year, "-", bayesian.sd_5$doy, sep = ""), format = "%Y-%j")
bayesian.sd_6$Date <- as.Date(paste(bayesian.sd_6$year, "-", bayesian.sd_6$doy, sep = ""), format = "%Y-%j")
bayesian.sd_7$Date <- as.Date(paste(bayesian.sd_7$year, "-", bayesian.sd_7$doy, sep = ""), format = "%Y-%j")
bayesian.res_0.5 <- bayesian.res_0.5[,c("Date", "GPPsd", "Rsd", "NEPsd")]
bayesian.res_0.5 <- bayesian.res_0.5[,c("Date", "GPP", "R", "NEP")]
bayesian.res_1 <- bayesian.res_1[,c("Date", "GPP", "R", "NEP")]
bayesian.res_2 <- bayesian.res_2[,c("Date", "GPP", "R", "NEP")]
bayesian.res_3 <- bayesian.res_3[,c("Date", "GPP", "R", "NEP")]
bayesian.res_4 <- bayesian.res_4[,c("Date", "GPP", "R", "NEP")]
bayesian.res_5 <- bayesian.res_5[,c("Date", "GPP", "R", "NEP")]
bayesian.res_6 <- bayesian.res_6[,c("Date", "GPP", "R", "NEP")]
bayesian.res_3 <- bayesian.res_7[,c("Date", "GPP", "R", "NEP")]
bayesian.sd_0.5 <- bayesian.sd_0.5[,c("Date", "GPPsd", "Rsd", "NEPsd")]
bayesian.sd_1 <- bayesian.sd_1[,c("Date", "GPPsd", "Rsd", "NEPsd")]
bayesian.sd_2 <- bayesian.sd_2[,c("Date", "GPPsd", "Rsd", "NEPsd")]
bayesian.sd_3 <- bayesian.sd_3[,c("Date", "GPPsd", "Rsd", "NEPsd")]
bayesian.sd_4 <- bayesian.sd_4[,c("Date", "GPPsd", "Rsd", "NEPsd")]
bayesian.sd_5 <- bayesian.sd_5[,c("Date", "GPPsd", "Rsd", "NEPsd")]
bayesian.sd_6 <- bayesian.sd_6[,c("Date", "GPPsd", "Rsd", "NEPsd")]
bayesian.sd_7 <- bayesian.sd_7[,c("Date", "GPPsd", "Rsd", "NEPsd")]
bayesian.res_0.5 <- bayesian.res_0.5[,c("Date", "GPP", "R", "NEP")]
bayesian.res_1 <- bayesian.res_1[,c("Date", "GPP", "R", "NEP")]
bayesian.res_2 <- bayesian.res_2[,c("Date", "GPP", "R", "NEP")]
bayesian.res_3 <- bayesian.res_3[,c("Date", "GPP", "R", "NEP")]
bayesian.res_4 <- bayesian.res_4[,c("Date", "GPP", "R", "NEP")]
bayesian.res_5 <- bayesian.res_5[,c("Date", "GPP", "R", "NEP")]
bayesian.res_6 <- bayesian.res_6[,c("Date", "GPP", "R", "NEP")]
bayesian.res_7 <- bayesian.res_7[,c("Date", "GPP", "R", "NEP")]
bayesian.res_7
bayesian.res_3
bayesian.res_3 <- metab(all5, method="bayesian", wtr.name='wtr', do.obs.name='do.obs',
irr.name='par', z.mix = "z.mix", k.gas.name = "k.gas",
do.sat.name = "do.sat")
bayesian.res_7 <- metab(all9, method="bayesian", wtr.name='wtr', do.obs.name='do.obs',
irr.name='par', z.mix = "z.mix", k.gas.name = "k.gas",
do.sat.name = "do.sat")
bayesian.sd_3 <- attr(bayesian.res_3, "metab.sd")
bayesian.sd_7 <- attr(bayesian.res_7, "metab.sd")
bayesian.res_3$Date <- as.Date(paste(bayesian.res_3$year, "-", bayesian.res_3$doy, sep = ""), format = "%Y-%j")
bayesian.res_7$Date <- as.Date(paste(bayesian.res_7$year, "-", bayesian.res_7$doy, sep = ""), format = "%Y-%j")
bayesian.res_3 <- bayesian.res_3[,c("Date", "GPP", "R", "NEP")]
bayesian.res_7 <- bayesian.res_7[,c("Date", "GPP", "R", "NEP")]
bayesian.sd_3$Date <- as.Date(paste(bayesian.sd_3$year, "-", bayesian.sd_3$doy, sep = ""), format = "%Y-%j")
bayesian.sd_7$Date <- as.Date(paste(bayesian.sd_7$year, "-", bayesian.sd_7$doy, sep = ""), format = "%Y-%j")
bayesian.sd_3 <- bayesian.sd_3[,c("Date", "GPPsd", "Rsd", "NEPsd")]
bayesian.sd_7 <- bayesian.sd_7[,c("Date", "GPPsd", "Rsd", "NEPsd")]
View(bayesian.res_7)
View(bayesian.res_3)
bayesian.merge_0.5 <- merge(bayesian.res_0.5, bayesian.sd_0.5, by = "Date")
bayesian.merge_1 <- merge(bayesian.res_1, bayesian.sd_1, by = "Date")
bayesian.merge_2 <- merge(bayesian.res_2, bayesian.sd_2, by = "Date")
bayesian.merge_3 <- merge(bayesian.res_3, bayesian.sd_3, by = "Date")
bayesian.merge_4 <- merge(bayesian.res_4, bayesian.sd_4, by = "Date")
bayesian.merge_5 <- merge(bayesian.res_5, bayesian.sd_5, by = "Date")
bayesian.merge_6 <- merge(bayesian.res_6, bayesian.sd_6, by = "Date")
bayesian.merge_7 <- merge(bayesian.res_7, bayesian.sd_7, by = "Date")
bayesian.merge_0.5$z.mix <- "0.5m"
bayesian.merge_1$z.mix <- "1m"
bayesian.merge_2$z.mix <- "2m"
bayesian.merge_3$z.mix <- "3m"
bayesian.merge_4$z.mix <- "4m"
bayesian.merge_5$z.mix <- "5m"
bayesian.merge_6$z.mix <- "6m"
bayesian.merge_7$z.mix <- "7m"
bayesian.merge.all <- rbind(bayesian.merge_0.5, bayesian.merge_1,
bayesian.merge_2, bayesian.merge_3, bayesian.merge_4,
bayesian.merge_5, bayesian.merge_6, bayesian.merge_7)
bayesian.merge.all
# GPP
p1 = ggplot(data = bayesian.merge.all, aes(x=Date, y=GPP, color=z.mix)) + theme_light() +
geom_line(data = subset(bayesian.merge.all, z.mix == "0.5m")) +
geom_errorbar(aes(ymin = GPP-GPPsd, ymax = GPP+GPPsd), width = 0.12) +
geom_line(data = subset(bayesian.merge.all, z.mix == "1m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "2m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "3m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "4m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "5m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "6m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "7m")) +
ylab(expression(paste("GPP (", O[2], " in mg L", NULL^-1, " day", NULL^-1, ")")))
# R
p2 = ggplot(data = bayesian.merge.all, aes(x=Date, y=R, color=z.mix)) + theme_light() +
geom_line(data = subset(bayesian.merge.all, z.mix == "0.5m")) +
geom_errorbar(aes(ymin = R-Rsd, ymax = R+Rsd), width = 0.12) +
geom_line(data = subset(bayesian.merge.all, z.mix == "1m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "2m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "3m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "4m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "5m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "6m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "7m"))
ylab(expression(paste("R (", O[2], " in mg L", NULL^-1, " day", NULL^-1, ")")))
# NEP
p3 = ggplot(data = bayesian.merge.all, aes(x=Date, y=NEP, color=z.mix)) + theme_light() +
geom_line(data = subset(bayesian.merge.all, z.mix == "0.5m")) +
geom_errorbar(aes(ymin = NEP-NEPsd, ymax = NEP+NEPsd), width = 0.12) +
geom_line(data = subset(bayesian.merge.all, z.mix == "1m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "2m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "3m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "4m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "5m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "6m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "7m"))
ylab(expression(paste("NEP (", O[2], " in mg L", NULL^-1, " day", NULL^-1, ")")))
ggplot(data = bayesian.merge.all, aes(x=Date, y=GPP, color=z.mix)) + theme_light() +
geom_line(data = subset(bayesian.merge.all, z.mix == "0.5m")) +
geom_errorbar(aes(ymin = GPP-GPPsd, ymax = GPP+GPPsd), width = 0.12) +
geom_line(data = subset(bayesian.merge.all, z.mix == "1m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "2m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "3m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "4m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "5m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "6m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "7m")) +
ylab(expression(paste("GPP (", O[2], " in mg L", NULL^-1, " day", NULL^-1, ")")))
ggplot(data = bayesian.merge.all, aes(x=Date, y=R, color=z.mix)) + theme_light() +
geom_line(data = subset(bayesian.merge.all, z.mix == "0.5m")) +
geom_errorbar(aes(ymin = R-Rsd, ymax = R+Rsd), width = 0.12) +
geom_line(data = subset(bayesian.merge.all, z.mix == "1m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "2m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "3m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "4m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "5m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "6m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "7m"))
ylab(expression(paste("R (", O[2], " in mg L", NULL^-1, " day", NULL^-1, ")")))
ggplot(data = bayesian.merge.all, aes(x=Date, y=NEP, color=z.mix)) + theme_light() +
geom_line(data = subset(bayesian.merge.all, z.mix == "0.5m")) +
geom_errorbar(aes(ymin = NEP-NEPsd, ymax = NEP+NEPsd), width = 0.12) +
geom_line(data = subset(bayesian.merge.all, z.mix == "1m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "2m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "3m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "4m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "5m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "6m")) +
geom_line(data = subset(bayesian.merge.all, z.mix == "7m"))
ylab(expression(paste("NEP (", O[2], " in mg L", NULL^-1, " day", NULL^-1, ")")))
View(all)
# Plots of ecosystem parameters
p4 = ggplot((all)) + theme_light() +
geom_line(aes(y=do.obs, x=datetime), color = "gray17") +
rremove("xlab") +
ylab(expression(paste("DO (mg L",NULL^-1,")")))
p5 = ggplot((all)) + theme_light() +
geom_line(aes(y=do.sat, x=datetime), color = "gray17") +
rremove("xlab") +
ylab(expression(paste("Equilibrium\nDO concentration (mg L",NULL^-1,")")))
p6 = ggplot((all)) + theme_light() +
geom_line(aes(y=wtr, x=datetime), color = "gray17") +
rremove("xlab") +
ylab("Temperature in °C")
p7 = ggplot((all)) + theme_light() +
geom_line(aes(y=par, x=datetime), color = "gray17") +
rremove("xlab") +
ylab(expression(paste("PAR (",mu,"mol m",NULL^-2," s",NULL^-1,")")))
p8 = ggplot((all)) + theme_light() +
geom_line(aes(y=k.gas, x=datetime), color = "gray17") +
rremove("xlab") +
ylab(expression(paste("Gas and temperature specific\ngas transfer coefficient (m",NULL^-1,")")))
p9 = ggplot((all)) + theme_light() +
geom_line(aes(y=wnd, x=datetime), color = "gray17") +
rremove("xlab") +
ylab("Wind speed (m/s)")
fig2 <- ggarrange(p1 + rremove("xlab"), p2 + rremove("xlab"), p3 + rremove("xlab"),
p4 + rremove("xlab"), p5 + rremove("xlab"), p6 + rremove("xlab"),
p7 + rremove("xlab"), p8 + rremove("xlab"), p9 + rremove("xlab"),
nrow=5, ncol = 2,  common.legend = TRUE, legend = "right")
annotate_figure(fig2, top = text_grob("Sensitivity analysis for z.mix in pond ERL85, 2021"))
png("../results_SensAnalysis/SensAnalysisZmix_ERL85_2021.png", width = 2000,
height = 1500, res = 150)
annotate_figure(fig2, top = text_grob("Sensitivity analysis for z.mix in pond ERL85, 2021"))
dev.off()
