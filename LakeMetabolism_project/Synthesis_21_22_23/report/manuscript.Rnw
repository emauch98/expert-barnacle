%%
%% Camera-ready submissions do not need line numbers, and
%% should have this option removed.
%%

\documentclass[11pt,lineno]{manuscript}
%\setlength{\mathindent}{0pt}
%%\usepackage{setspace}
%%\doublespacing
\usepackage{soul}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=blue,      
    urlcolor=blue,
    citecolor=blue,
    }


\newcommand{\beginsupplement}{%
        \setcounter{table}{0}
        \renewcommand{\thetable}{S\arabic{table}}%
        \setcounter{figure}{0}
        \renewcommand{\thefigure}{S\arabic{figure}}%
     }

\title{Template for manuscript}

\author[1]{Author One}
\author[1]{Author Two}
\author[2,3]{Author Three}
\author[1]{Author Four}
\affil[1]{Author one affiliation}
\affil[2]{Author two affiliation}
\affil[3]{Author three affiliation}

\corrauthor[1]{Author Four}{email@address}

\keywords{Keyword1; Keyword2; Keyword3}

\begin{abstract}
This is the abstract.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R specifications
<<setup, include = FALSE>>=
# knitr
library(knitr)
opts_chunk$set(fig.path = 'plots/p', 
               echo = FALSE, 
               fig.align = "center",
               cache = TRUE)

# packages
require(LakeMetabolizer) # Modeling Lake Metabolism
require(dplyr) # data wrangling
require(xtable) # generating latex tables from datasets
require(data.table) # data wrangling
require(readxl) # importing excel tables

@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\flushbottom
\maketitle
\thispagestyle{empty}

\section*{Introduction}
...

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Materials and Methods}
...

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Results}
...
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Discussion}
...

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Conclusions}
...

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Author contributions}
...

\section*{Institutional review}
...

\section*{Data availability} 
...

\section*{Funding}
...

\section*{Acknowledgments}
...

\section*{Conflicts of interest}
...

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliography{main}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage

\beginsupplement
\renewcommand\figurename{Supplementary Figure}
\renewcommand\tablename{Supplementary Table}

\section*{Appendix}

\subsection{Study design and setup} \label{subsec:design}

In 2019, 12 glacial lakes ($N =$ 12) were chosen for an experiment near Narsarsuaq,
Greenland (61.1567\textdegree{}N, -45.4254\textdegree{}E).
These glacial lakes vary in area (0.21 to 1.82 hectares) and maximum
depth (2 to 8 m), but are all clustered within a few
kilometers of each other. All lakes were fishless at the beginning of the experiment.
Six lakes were subsequently introduced with three-spined sticklebacks
(\textit{Gasterosteus aculeatus}) from nearby lakes.
Lake B1P1, B2P2, and B3P3 were introduced with \textit{Gasterosteus aculeatus} from a single
population (lake L26, 61.253333\textdegree{}N, -45.529141\textdegree{}E),
while lake B2P3, B3P1, and B3P2 were introduced with \textit{Gasterosteus aculeatus} from
two populations (lake L26, 61.253333\textdegree{}N, -45.529141\textdegree{}E
and lake ERL33, 61.118369\textdegree{}N, -45.580845\textdegree{}E).
The remaining six lakes B1P4, B2P4, B3P0, ERL85, ERL122, and ERL152 were
used as fishless control. For the purpose of this study, the origin
of the introduced \textit{Gasterosteus aculeatus} is of minor importance,
as they all originate from the same area (Supplementary Table~\ref{tab:lakes}).

In 2021, 2022, and 2023, all 12 lakes were monitored over several days.
For that purpose, EXO2 multiparameter sondes were installed
(YSI, Yellow Springs, OH, USA), tracking ecosystem parameters with high
frequency (2-minute intervals in 2021 and 2022, 5-minute intervals in
2023 with the exception of ERL122, which was monitored in 15-minute intervals).
For the purpose of this study, only dissolved oxygen (hereafter DO) and temperature measurements
yielded from these sondes are relevant. The sensors were situated at a water depth
of approximately 1-1.5 m in each lake. All optical sensors were
wiped clean before every measurement with a built-in wiper.
The monitoring period was 16 September-24 September in 2021, 22 June-3 July in 2022,
and 22 June-17 July in 2023.

<<laketable, results = "asis", echo=FALSE>>=
# Import lakemaster file
lakes <- read_excel("../../Organisation/GL_Lake_Master.xlsx")

# Extract relevant ponds
lakes <- lakes[c(18:23, 73:75, 78, 28, 83),]

# Extract columns
lakes <- lakes[,c("Lake", "Lat", "Long", "Areaha", "Altitude", "Depth")]

# Rename lakes
lakes$Lake <- c("B1P1", "B2P2", "B3P3", "B2P3", "B3P1", "B3P2", "B1P4", "B2P4",
                "B3P0", "ERL85", "ERL122", "ERL152")

# Rename
setnames(lakes, c("Lake", "Latitude (°N)", "Longitude (°E)", "Area (hectare)",
                  "Altitude (m)", "Maximum Depth (m)"))

# Create treatment variable
lakes$Treatment <- c("Fish","Fish","Fish","Fish","Fish","Fish",
                   "No Fish","No Fish","No Fish","No Fish","No Fish","No Fish")

# Reorder
lakes <- lakes[,c("Lake", "Treatment", "Latitude (°N)",
                  "Longitude (°E)", "Altitude (m)", "Area (hectare)",
                  "Maximum Depth (m)")]

# Make a latex table from dataset
lakes <- xtable(lakes, align = c("l","l","l","l","l","l","l","l"),
                digits = c(0,0,0,5,5,0,2,2),
                caption = "Lakes included in the experiment, along with treatment
                and general characteristics.", label = "tab:lakes")

# Print
print(lakes, include.rownames = FALSE, caption.placement = "top", booktabs = TRUE)
@

\subsection{Data sources} \label{subsec:source}

DO ($mg\,L^{-1}$) and water temperature (\textdegree{}$C$) measurements
were yielded from EXO2 multiparameter
sondes, as described in section~\nameref{subsec:design}. For the purpose
of estimating ecosystem metabolism, wind and irradiation data were yielded
from the Programme for Monitoring of the Greenland Ice Sheet (PROMICE), providing automatic
weather station data \citep{Fausto:2021}.
The dataset named \texttt{QAS\_L\_hour.csv} originating from the QAS\_L automated weather station
near Narsarsuaq was downloaded from a
\href{https://dataverse.geus.dk/citation?persistentId=doi:10.22008/FK2/IW73UU}{public database}
provided by PROMICE \citep{metadata}.
Wind data was provided as average wind speed in hourly intervals ($m\,s^{-1}$), while
irradiation was provided as downwelling shortwave irradiation additionally
corrected for the tilt of the sensor ($W\,m^{-2}$).

\subsection{Data pipeline} \label{subsec:pipeline}

The data preparation and analysis for estimating lake metabolism was done separately for each monitoring
period (16 September-24 September 2021, 22 June-3 July 2022, and 22 June-17 July 2023).

First, the raw sonde data from each lake were imported and merged into
one dataset for a given monitoring period. The variables required for lake metabolism
estimation were water temperature and
DO. Next, an outlier analysis was performed by removing
values higher than three times the median absolute deviation of all values in a
sliding window of one day window size \citep{Luerig:2021}.
After outlier removal, the time series of water temperature and DO
were plotted and subsequently investigated for larger data gaps due to potential lack of sensor
measurements over certain periods.

To ensure overlapping estimation of lake metabolism, the data was subsequently
cut to achieve equal starting and ending time points for all lakes during a given
monitoring period. Due to large data gaps during the period of 2022, we chose
to keep as much complete days as possible in order to estimate the maximum
amount of days, rather than selecting the longest common monitoring period
for all lakes.

After cutting the sonde data, they were subsequently merged with the weather data.
Since the weather data were collected in hourly intervals, they were inflated to match
the measurement intervals of the sonde data (see section \nameref{subsec:design}).

After merging sonde and weather data, potential missing values due to outlier removal
were imputed by a weighted moving average, where the weights of observations around the
central value to be imputed decrease exponentially \citep{Moritz:2017}.
For larger data gaps spanning over several hours (due to sonde malfunction rather
than outlier removal), we chose
to not estimate lake metabolism for the affected days.\smallskip

All data preparation and analysis was done with the \texttt{R} programming language \citep{R}.
To estimate lake metabolism, the package \texttt{LakeMetabolizer} was used \citep{Winslow:2016}.
Specifically, a Bayesian framework to estimate whole lake metabolism from free-water
DO by using the function \texttt{metab.bayesian} was chosen for
this analysis \citep{Holtgrieve:2010}.
In order to be able to fit the model, a minimum of 6 variables are needed as input:

\begin{enumerate}
\item doobs: DO concentration measurements ($mg\,L^{-1}$)
\item do.sat: Equilibrium DO concentration for specific temperature ($mg\,L^{-1}$, hereafter do.sat)
\item k.gas: Gas and temperature specific gas transfer coefficient ($m^{-1}$, hereafter k.gas)
\item par: Photosynthetically active radiation ($\mu{}mol\,m^{-2}\,s^{-1}$, hereafter par)
\item z.mix: Actively mixed layer depth ($m$, hereafter z.mix)
\item wtr: Water temperature (\textdegree{}$C$)
\end{enumerate}

Some of the variables listed above have to be derived from other time series data prior
to estimating lake metabolism,
namely do.sat, k.gas, par, and z.mix. The necessary functions are provided by the
\texttt{LakeMetabolizer} package.
do.sat was derived by using the function \texttt{o2.at.sat}, which calculates
the equilibrium DO concentration in water at supplied conditions.
To estimate k.gas, a gas transfer coefficient model must be fit.
The \texttt{LakeMetabolizer} package offers different methods, and we chose
an empirical wind-based gas exchange model, introduced by Vachon and
Prairie in 2013 \citep{Vachon:2013}. This model not only takes wind into
consideration, but also lake area, and is implemented in the function
\texttt{k.vachon}. Notably, wind speed has to be normalized
to 10 $m$ sensor height before fitting any gas exchange model, which is achieved
with the function \texttt{wind.scale}.
All models of gas exchange 
return a k\textsubscript{600} value, a gas exchange normalized to a Schmidt 
number (Sc) of 600, or O\textsubscript{2} at 17.5 \textdegree{}$C$.
After estimating k\textsubscript{600}, it must be transformed to k.gas by using the
function \texttt{k600.2.kGAS}. par was derived from shortwave irradiation,
which we had available (see section \nameref{subsec:source}).
To achieve this transformation, we used the function \texttt{sw.to.par},
which uses the simple empirical transformation $par = 2.114 \times sw$ \citep{Britton:1976}.
To estimate z.mix, one normally needs a time series profile of water temperature
or water density. Since we did not have such data available, we decided to
simulate actively mixed layer depth by drawing from a uniform distribution
with limits 0 and maximum depth of the lake. The reasoning behind this simulation
is that, although the simulated time series of z.mix likely differing substantially
from the actual, a possible treatment effect of fish versus no fish should still be
consistent, given the simulation is performed equally in all lakes.\smallskip

After performing the data preparation and the derivation for certain model
inputs, the Bayesian lake metabolism model was fitted for each lake and
monitoring period. The Bayesian model is special, as it considers 2 types
of errors: Differences between the true data generating process and the process
defined in the model (process error) and errors resulting from inaccuracies
of DO measurements (observation error). Reflecting this philosophy, the
Bayesian model distinguishes between 3 categories of DO values: $y$ represents
the DO measurements, $\alpha$ the true but unknown DO values, and
$\alpha^{\ast}$ the model's estimates of the true value.
The observed DO measurements $y$ are modeled as random deviations from the true
value $\alpha$:

\begin{equation}
y_{t} \sim N(\alpha_{t}, \tau_{v}),
\label{eq:doobs}
\end{equation}

where $\tau_{v}$ is the precision of the observation error (precision is
the reciprocal of variance).
Note, that the Bayesian model fits parameter values by making a comparison
between observed and theoretical values of DO.
This comparison is made in equation \ref{eq:dotrue}, where we define the true value of 
DO at time $t$, $\alpha_{t}$, as being normally distributed with mean 
$\alpha^{\ast}_{t}$ and process precision $\tau_{w}$:

\begin{equation}
\alpha_{t} \sim N(\alpha^{\ast}_{t}, \tau_{w}),
\label{eq:dotrue}
\end{equation}

where $\tau_{w}$ is the precision of the process error.
The important distinction of process and observation error is that
process error affects the state of the system at time
$t + k (k=0, 1, ..., T-t)$, because the state evolves dynamically, whereas
observation error only affects the state of the system at time $t$.

Both $\tau_{v}$ and $\tau_{w}$ are given minimally informative priors
following a gamma distribution with shape and rate parameters of 0.001.

The Bayesian model can be described by the following equations:

\begin{gather}
\alpha^{\ast}_{t} =
\begin{cases}
\alpha_{t-1} + \alpha_{t} & \text{if } k_{t} = 0, \\
\frac{\alpha_{t}}{k_{t-1}} + \frac{-\exp{(-k_{t-1})}\alpha_{t}}{k_{t-1}} +
\exp{(-k_{t-1})}\alpha_{t-1} & \text{otherwise},
\end{cases} \label{eq:sys1} \\
\alpha_{t} = \mathbf{X}_{t-1}\bm{\beta} + k_{t-1}O_{s,t-1}, \label{eq:sys2} \\
k_{t} = \frac{K^{\ast}_{t}\Delta t}{z_{t}}. \label{eq:sys3}
\end{gather}

In this equation structure, $k_{t}$ is the coefficient of gas exchange;
$\mathbf{X}$ is an $n \times 2$ matrix of predictor variables with $I$
(irradiation in arbitrary light units) in the first column and $\ln{T}$ (\textdegree{}$C$) in the second
column; $\bm{\beta}$ is a $2 \times 1$ vector of parameters to be estimated
($\iota$, $\rho$). $\iota$ represents the parameter for Gross Primary Production
(hereafter GPP), implying a linear relationship between GPP and irradiation, and $\rho$ represents
the parameter for Respiration (hereafter R), implying a log-linear relationship
between R and temperature; $O_{s}$ is the equilibrium DO concentration at
supplied conditions; $K^{\ast}_{t}$ is a stochastic node,
with $K^{\ast}_{t} \sim N(K_{t}, \sigma_{k})$, where $K_{t}$ is the gas exchange
coefficient, and $\sigma_{k}$ the precision thereof; the default precision
is $1/(0.1 \times K_{t})$; finally, $z_{t}$ is the mixed layer depth.

From equation~\ref{eq:sys1}, we can see that if $k_{t} = 0$ (i.e., no gas exchange
with the atmosphere), the oxygen levels in the water are modeled to be additive for each
time step. Furthermore, we can see that the gas exchange coefficient is dependent
on mixed layer depth (equation~\ref{eq:sys3}).

While the estimate of gas exchange coefficient serves as prior information for $K$,
priors for the fitted GPP and R parameters ($\iota$ and $\rho$) can also
be defined. The default priors for $\iota$ and $\rho$ are normal distributions
with mean 0 and variance $1 \times 10^{5}$
($\iota_{t} \sim N(0,10^{5})$, $\rho_{t} \sim N(0,10^{5})$) and were used in our case.

To estimate metabolism, the median of the posterior distribution of the parameters
is used as a scalar estimate. Daily GPP and R estimates represent an integrated
estimate of these scalars over a 24-hour window. Uncertainty of GPP and R
estimates is expressed as the posterior standard deviation of the respective
parameters ($\iota$ and $\rho$), multiplied by the square root of the corresponding
covariate ($I$ and $\ln{T}$). NEP is the sum of GPP and R, and the standard deviation
of NEP is the sum of the standard deviations for GPP and R.

In total, 5 parameters are fit in this Bayesian model, namely $\iota$, $\rho$,
$K$, $\tau_{v}$, and $\tau_{w}$. For all parameters except $K$, (default) minimally
informative priors were used. Regarding $K$, as described above, its estimate
(from the separate gas transfer coefficient model) serves as a prior.

Estimates of the posterior distribution of the parameters were sampled using
Gibbs sampling implemented in Just Another Gibbs Sampler
(\href{https://sourceforge.net/projects/mcmc-jags/files/}{JAGS}). Prior to running
the Bayesian model, it must be installed.

\subsection{Sensitivity analysis for mixed layer depth} \label{subsec:sens}

As mentioned in section~\nameref{subsec:pipeline}, we did not have the necessary
data to estimate mixed layer depth. An initial approach to assess this issue
was to investigate the effect of different mixed layer depths on daily metabolism
estimates. For that purpose, we selected a few lakes for different monitoring
periods (2021, 2022, 2023). Notably, mixed layer
was held constant, which is rarely the case in reality.
In Figure~\ref{fig:sens}, an example of a sensitivity analysis for lake
B1P1 in 2021 is depicted. Plots A-C depict the daily GPP, R, and NEP estimates
for different mixed layer depths. For each mixed layer value, a separate model
was fitted, holding all other covariates equal.
Apparently, mixed layer depth substantially
impacts respiration, where a smaller mixed layer depth is associated with
higher (more negative) R. In contrast, GPP is barely affected by mixed
layer depth. Plots D-H show the input variables required to fit the metabolism
models, apart from mixed layer depth. Since mixed layer particularly
effects daily R estimates, careful consideration with regards to overcoming
this limitation is required. Notably, the effect of variation in mixed layer
depth was consistent across most lakes and monitoring periods

<<sensanal1, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE>>=
# Packages ad functions from Moritz Luehrig's paper
source("../../Literature/Moritz_Luehrig_paper_stuff/methods_packages.R")

# Estimating lake metabolism with free-water oxygen
# See "report_analysis_metabolism_B3P3_2022" for further details
require(LakeMetabolizer)

# For plotting
require(GGally)

# Imputation of NAs for time-series (our NAs are due to outlier processing)
require(imputeTS)

# For Bayesian lake metabolism modeling
require(R2jags) # Also, installing JAGS is necessary under
# http://www.sourceforge.net/projects/mcmc-jags/files

require(ggpubr)
require(grid) # Arranging multiple plots
require(grDevices) # Saving png files

# This is our complete dataset of the sondes measurements 2021
# Measurement Interval: 2 minutes
all <- fread("../../project_21/data/processed_data_sondes/ponds_sonde_data_all.txt")

# Importing the metadata
# Wind and irradiation
# Measurement Interval: 1 hour, hourly averages
# Source: QAS_L automated weather station near Narsarsuaq
# https://dataverse.geus.dk/dataset.xhtml?persistentId=doi:10.22008/FK2/IW73UU
# wind sensor height: 2.65 + 0.4 = ca 3.05m
meta <- fread("../../project_21/data/metadata_metabolism_analysis/metadata_2021.txt")

# Step 1: data formatting ------------------------------------------------------

# Select columns to keep from our time series
all <- all[, c("Pond", "Date_time", "ODO_mgL", "Temp_C")]

# Select Pond B1P1 (Treatment: Fish)
all <- subset(all, Pond == "B1P1")

# Rename
all <- setnames(all,c("Pond", "datetime", "do.obs", "wtr"))

# Isolate the desired period (described in the introduction)
# Unfortunately, B1P1 had a huge data-gap so we can only estimate
# metabolism before (we have 4 complete days)
all <- all[c(121:3000),]

# choose desired period for the metadata
meta <- meta[c(1:97),]

# rename
meta <- setnames(meta,c("datetime", "dsr_cor", "wsp"))

meta <- meta %>%
  mutate(datetime = as.POSIXct(format(datetime, format = "%Y-%m-%d %H:01:00", tz = "UTC"), tz = "UTC"))

# Create a new inflated dataset with measurements every 2 minutes
# The hourly mean will be assigned to every observation (2min-interval) within that hour
meta_ext <- meta %>%
  complete(datetime = seq(from = min(datetime), to = max(datetime), by = "2 min"))

# Fill the missing wind speed and irradiation values with the corresponding hourly values using 'fill'
meta_ext <- meta_ext %>%
  fill(wsp, .direction = "up") %>%
  fill(dsr_cor, .direction = "up")

# Shift wind speed and irradiation one row up
meta_ext <- meta_ext %>%
  mutate(wsp = lead(wsp, default = last(wsp))) %>%
  mutate(dsr_cor = lead(dsr_cor, default = last(dsr_cor)))

# Ommit last row (not included in our timeseries)
meta_ext <- meta_ext[-nrow(meta_ext), ]

# Reset row names for the final result
rownames(meta_ext) <- NULL

# Step 2: merge the 2 datasets -------------------------------------------------
all <- merge(meta_ext, all, by = "datetime")

# Step 3: Missing data imputation ----------------------------------------------
# We need a complete ODO_mgL timeseries. Therefore we will impute the missing values
# here, with the package "imputeTS", which is specifically designed to impute time-series
# observations.

# 113 NAs (due to outlier processing)
# colSums(is.na(all))

# Make a timeseries object
ts <- ts(all$do.obs, frequency = 720)

# Impute with imputeTS
imp_all <- na_ma(ts) # use this function!
imp_all <- data.table(imp_all)
imp_all$datetime <- all$datetime

# Check for missing values in the imputed dataset
#sum(is.na(imp_all)) # No missing values anymore

# Check imputation by plotting the original and the imputed dataset
# plot(x = all$datetime, y = all$do.obs, type = "l", col = "blue", lwd = 2)
# lines(x = imp_all$datetime, y = imp_all$imp_all, type = "l",
#       col = rgb(1, 0, 0, alpha = 0.3), lwd = 2)
# The imputation worked very well!

# Replace original column with imputed column
all$do.obs <- imp_all$imp_all
# sum(is.na(all))

# Step 4: Model choice ---------------------------------------------------------
# Gas transfer coefficient model: kvachon()
# - needs wind speed, sensor height, and lake area

# Lake metabolism model: metab.bayesian()
# Most flexible model

# Step 5: Calculate k600 using the Cole method ---------------------------------

# This function needs specific column names
all$wnd <- all$wsp
all$wsp <- NULL

# Normalize wind to 10m sensor height
wind.scale <- wind.scale(all, wnd.z = 3.05)

all <- merge(all, wind.scale, by = "datetime")

all$wnd <- all$wnd_10
all$wnd_10 <- NULL

# Also only the 2 columns of interest, otherwise it gets confused
all.600 <- all[,c("datetime","wnd")]
k600.vachon <- k.vachon(all.600, lake.area = 2100)

# Merge
all <- merge(all, k600.vachon, by = "datetime")

# Step 6: Calculate gas-specific k600 ------------------------------------------

kgas <- k600.2.kGAS(all)

# Merge
all <- merge(all, kgas, by = "datetime")

# only keep k.gas
all$k600 <- NULL

# Step 7: Calculate dissolved oxygen saturated (do.sat) ------------------------

# I know that the sonde has do.sat measurements, but I have more faith
# in the authors of this paper to calculate a more accurate do.sat then the
# sonde-intern calculations.

o2.sat <- o2.at.sat(all[,c('datetime','wtr')])

# Merge
all <- merge(all, o2.sat, by = "datetime")

# Step 8: Derive photosynthetically active radiation (par) from shortwave irradiation (sw) ----
# Here, I take the downwelling shortwave irradiation (tilt corrected) from the
# QAS_L automated weather station a couple of kilometers away from Narsarsuaq
# It's the closest weather station measuring this parameter, that I could find.

# Derive par from sw
par <- sw.to.par(all, sw.col = "dsr_cor")
rownames(par) <- NULL

# Merge
all <- merge(all, par[,c("datetime", "par")], by = "datetime")

# Step 9: Calculate Actively mixed layer depth (z.mix) -------------------------

################################################################################
# The max depth of pond B1P1 is about 4m.
# According to the profiling plots, B1P1 had an actively mixed layer depth of
# about 2m on Sept 10 2021.
# We will fit a model with mixed layer depth of 0.5, 1, 2, and 3 meters for this pond.
# The ponds maximum depth is 4m.
################################################################################

# Set different mixed layer depths of sensitivity analysis
# For some reason, metab.bayesian does not recognize z.mix columns
# if they are not named "z.mix", hence I have to create a dataset for each z.mix
all2 <- all
all2$z.mix <- 0.5

all3 <-all
all3$z.mix <- 1

all4 <- all
all4$z.mix <- 2

all5 <- all
all5$z.mix <- 3

# Step 10: Fit model -----------------------------------------------------------

# Choose columns to keep
all2 <- all2[,c("datetime", "do.obs", "do.sat", "k.gas", "z.mix", "par", "wtr")]
all3 <- all3[,c("datetime", "do.obs", "do.sat", "k.gas", "z.mix", "par", "wtr")]
all4 <- all4[,c("datetime", "do.obs", "do.sat", "k.gas", "z.mix", "par", "wtr")]
all5 <- all5[,c("datetime", "do.obs", "do.sat", "k.gas", "z.mix", "par", "wtr")]

capture.output({
  # Mixed layer depth 0.5m over the whole observation period
bayesian.res_0.5 <- metab(all2, method="bayesian", wtr.name='wtr', do.obs.name='do.obs',
                      irr.name='par', z.mix = "z.mix", k.gas.name = "k.gas",
                      do.sat.name = "do.sat")

# Mixed layer depth 1m over the whole observation period
bayesian.res_1 <- metab(all3, method="bayesian", wtr.name='wtr', do.obs.name='do.obs',
                        irr.name='par', z.mix = "z.mix", k.gas.name = "k.gas",
                        do.sat.name = "do.sat")

# Mixed layer depth 2m over the whole observation period
bayesian.res_2 <- metab(all4, method="bayesian", wtr.name='wtr', do.obs.name='do.obs',
                        irr.name='par', z.mix = "z.mix", k.gas.name = "k.gas",
                        do.sat.name = "do.sat")

# Mixed layer depth 3m over the whole observation period
bayesian.res_3 <- metab(all5, method="bayesian", wtr.name='wtr', do.obs.name='do.obs',
                        irr.name='par', z.mix = "z.mix", k.gas.name = "k.gas",
                        do.sat.name = "do.sat")
}, file = "NUL")
@

\vspace{0.5cm}
<<sensanal2, results='asis', fig.cap= "\\label{fig:sens}Example of a sensitivity analysis for mixed layer depth in lake B1P1, 2021. Figures A-C depict GPP, R, and NEP estimates for different mixed layer depths. Figures D-H depict time series of input variables needed for metabolism estimation.", fig.align='center',fig.height=7.5>>=
# Get standard deviations of estimates
bayesian.sd_0.5 <- attr(bayesian.res_0.5, "metab.sd")
bayesian.sd_1 <- attr(bayesian.res_1, "metab.sd")
bayesian.sd_2 <- attr(bayesian.res_2, "metab.sd")
bayesian.sd_3 <- attr(bayesian.res_3, "metab.sd")

# Create a date variable
bayesian.res_0.5$Date <- as.Date(paste(bayesian.res_0.5$year, "-", bayesian.res_0.5$doy, sep = ""), format = "%Y-%j")
bayesian.res_1$Date <- as.Date(paste(bayesian.res_1$year, "-", bayesian.res_1$doy, sep = ""), format = "%Y-%j")
bayesian.res_2$Date <- as.Date(paste(bayesian.res_2$year, "-", bayesian.res_2$doy, sep = ""), format = "%Y-%j")
bayesian.res_3$Date <- as.Date(paste(bayesian.res_3$year, "-", bayesian.res_3$doy, sep = ""), format = "%Y-%j")

# Select columns to keep
bayesian.res_0.5 <- bayesian.res_0.5[,c("Date", "GPP", "R", "NEP")]
bayesian.res_1 <- bayesian.res_1[,c("Date", "GPP", "R", "NEP")]
bayesian.res_2 <- bayesian.res_2[,c("Date", "GPP", "R", "NEP")]
bayesian.res_3 <- bayesian.res_3[,c("Date", "GPP", "R", "NEP")]

# Create a date variable
bayesian.sd_0.5$Date <- as.Date(paste(bayesian.sd_0.5$year, "-", bayesian.sd_0.5$doy, sep = ""), format = "%Y-%j")
bayesian.sd_1$Date <- as.Date(paste(bayesian.sd_1$year, "-", bayesian.sd_1$doy, sep = ""), format = "%Y-%j")
bayesian.sd_2$Date <- as.Date(paste(bayesian.sd_2$year, "-", bayesian.sd_2$doy, sep = ""), format = "%Y-%j")
bayesian.sd_3$Date <- as.Date(paste(bayesian.sd_3$year, "-", bayesian.sd_3$doy, sep = ""), format = "%Y-%j")

# Select columns to keep
bayesian.sd_0.5 <- bayesian.sd_0.5[,c("Date", "GPPsd", "Rsd", "NEPsd")]
bayesian.sd_1 <- bayesian.sd_1[,c("Date", "GPPsd", "Rsd", "NEPsd")]
bayesian.sd_2 <- bayesian.sd_2[,c("Date", "GPPsd", "Rsd", "NEPsd")]
bayesian.sd_3 <- bayesian.sd_3[,c("Date", "GPPsd", "Rsd", "NEPsd")]

bayesian.merge_0.5 <- merge(bayesian.res_0.5, bayesian.sd_0.5, by = "Date")
bayesian.merge_1 <- merge(bayesian.res_1, bayesian.sd_1, by = "Date")
bayesian.merge_2 <- merge(bayesian.res_2, bayesian.sd_2, by = "Date")
bayesian.merge_3 <- merge(bayesian.res_3, bayesian.sd_3, by = "Date")

# create Z.mix variable identifier
bayesian.merge_0.5$z.mix <- "0.5m"
bayesian.merge_1$z.mix <- "1m"
bayesian.merge_2$z.mix <- "2m"
bayesian.merge_3$z.mix <- "3m"

# Merge
bayesian.merge.all <- rbind(bayesian.merge_0.5, bayesian.merge_1,
                            bayesian.merge_2, bayesian.merge_3)

# Step 11: Visualize the results -----------------------------------------------

# GPP
p1 <- ggplot(data = bayesian.merge.all, aes(x = Date, y = GPP, linetype = z.mix)) + 
  theme_light() +
  geom_line() +
  geom_errorbar(aes(ymin = GPP - GPPsd, ymax = GPP + GPPsd), width = 0.12,
                linetype = "solid") +
  scale_linetype_manual(
    values = c("0.5m" = "solid", "1m" = "dashed", "2m" = "dotted", "3m" = "dotdash")
  ) +
  ylab(expression(paste("GPP (", O[2], " in mg L", NULL^-1, " day", NULL^-1, ")"))) +
  labs(linetype = "Mixed layer depth")

# R
p2 <- ggplot(data = bayesian.merge.all, aes(x=Date, y=R, linetype=z.mix)) + theme_light() +
  geom_line() +
  geom_errorbar(aes(ymin = R-Rsd, ymax = R+Rsd), width = 0.12,
                linetype = "solid") +
  scale_linetype_manual(
    values = c("0.5m" = "solid", "1m" = "dashed", "2m" = "dotted", "3m" = "dotdash")
  ) +
  ylab(expression(paste("R (", O[2], " in mg L", NULL^-1, " day", NULL^-1, ")"))) +
  labs(linetype = "Mixed layer depth")


# NEP
p3 = ggplot(data = bayesian.merge.all, aes(x=Date, y=NEP, linetype=z.mix)) + theme_light() +
  geom_line() +
  geom_errorbar(aes(ymin = NEP-NEPsd, ymax = NEP+NEPsd), width = 0.12,
                linetype = "solid") +

  scale_linetype_manual(
    values = c("0.5m" = "solid", "1m" = "dashed", "2m" = "dotted", "3m" = "dotdash")
  ) +
  ylab(expression(paste("NEP (", O[2], " in mg L", NULL^-1, " day", NULL^-1, ")"))) +
  labs(linetype = "Mixed layer depth")

# Plots of ecosystem parameters
p4 = ggplot((all)) + theme_light() +
  geom_line(aes(y=do.obs, x=datetime)) +
  rremove("xlab") +
  ylab(expression(paste("DO (mg L",NULL^-1,")")))

p5 = ggplot((all)) + theme_light() +
  geom_line(aes(y=do.sat, x=datetime)) +
  rremove("xlab") +
  ylab(expression(paste("DO.sat (mg L",NULL^-1,")")))

p6 = ggplot((all)) + theme_light() +
  geom_line(aes(y=wtr, x=datetime)) +
  rremove("xlab") +
  ylab("Temperature (°C)")

p7 = ggplot((all)) + theme_light() +
  geom_line(aes(y=par, x=datetime)) +
  rremove("xlab") +
  ylab(expression(paste("PAR (",mu,"mol m",NULL^-2," s",NULL^-1,")")))

p8 = ggplot((all)) + theme_light() +
  geom_line(aes(y=k.gas, x=datetime)) +
  rremove("xlab") +
  ylab(expression(paste("Gas transfer coefficient (m",NULL^-1,")")))

fig2 <- ggarrange(p1 + rremove("xlab"), p2 + rremove("xlab"), p3 + rremove("xlab"),
                  p4 + rremove("xlab"), p5 + rremove("xlab"), p6 + rremove("xlab"),
                  p7 + rremove("xlab"), p8 + rremove("xlab"), nrow=4, ncol = 2,
                  common.legend = TRUE, legend = "top",
                  labels = c("A", "B", "C", "D", "E", "F", "G", "H"),label.x = -0.043,
                  align = "hv")

fig2 <- annotate_figure(fig2) +
  theme(plot.margin = margin(t = 5, r = 8, b = 5, l = 12))
print(fig2)
@
\vspace{0.5cm}








\end{document}

